#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”µè§†å‰§æ£€ç´¢å™¨ - é‡æ„ç‰ˆæœ¬
æ”¯æŒå¤šç§æ£€ç´¢æ¨¡å¼ï¼šæé€Ÿæ¨¡å¼ã€æ·±åº¦æ¨¡å¼ã€ç­›é€‰æ¨¡å¼
"""

import os
from typing import List, Optional, Dict, Literal
from llama_index.core import QueryBundle, VectorStoreIndex
from llama_index.core.schema import NodeWithScore
from llama_index.core.retrievers import VectorIndexRetriever
from llama_index.core.vector_stores import MetadataFilters, FilterCondition
from llama_index.core.postprocessor import SentenceTransformerRerank
import logging

# é…ç½®ç¯å¢ƒå˜é‡
if 'HF_ENDPOINT' not in os.environ:
    os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
os.environ['SAFETENSORS_FAST_GPU'] = '1'
os.environ.pop('HTTP_PROXY', None)
os.environ.pop('HTTPS_PROXY', None)
os.environ.pop('http_proxy', None)
os.environ.pop('https_proxy', None)
os.environ.pop('ALL_PROXY', None)
os.environ.pop('all_proxy', None)
os.environ['NO_PROXY'] = 'localhost,127.0.0.1,::1'
os.environ['no_proxy'] = 'localhost,127.0.0.1,::1'

from llama_index.core import Settings
from llama_index.llms.ollama import Ollama
from llama_index.embeddings.huggingface import HuggingFaceEmbedding

logger = logging.getLogger(__name__)


class TVShowRetriever:
    """
    ç”µè§†å‰§æ£€ç´¢å™¨ - ç»Ÿä¸€æ¥å£
    
    æ”¯æŒä¸‰ç§æ¨¡å¼ï¼š
    1. âš¡ æé€Ÿæ¨¡å¼ (Lightning): çº¯å‘é‡æ£€ç´¢ï¼Œå¿«é€Ÿè¿”å›
    2. ğŸ§  æ·±åº¦æ¨¡å¼ (Deep Thought): HyDEæŸ¥è¯¢é‡å†™ + åŒè½¨æ£€ç´¢ + Rerank
    3. ğŸ¯ ç­›é€‰æ¨¡å¼ (Filter): Metadataè¿‡æ»¤ + å‘é‡æ’åº
    """
    
    def __init__(
        self,
        rich_text_index: VectorStoreIndex,
        basic_index: Optional[VectorStoreIndex] = None,
        similarity_top_k: int = 30,
        rerank_top_k: int = 10,
        use_hyde: bool = False,
        similarity_cutoff: float = 0.2
    ):
        """
        Args:
            rich_text_index: å¯Œæ–‡æœ¬ç´¢å¼•
            basic_index: åŸºç¡€ç´¢å¼•ï¼ˆå¯é€‰ï¼‰
            similarity_top_k: åˆå§‹æ£€ç´¢æ•°é‡
            rerank_top_k: é‡æ’åºåä¿ç•™æ•°é‡
            use_hyde: æ˜¯å¦ä½¿ç”¨HyDEæŸ¥è¯¢é‡å†™
            similarity_cutoff: ç›¸ä¼¼åº¦é˜ˆå€¼
        """
        self.rich_text_index = rich_text_index
        self.basic_index = basic_index
        self.similarity_top_k = similarity_top_k
        self.rerank_top_k = rerank_top_k
        self.use_hyde = use_hyde
        self.similarity_cutoff = similarity_cutoff
        
        # åˆå§‹åŒ–Rerankerï¼ˆåœ¨æ£€ç´¢å™¨å†…éƒ¨ä½¿ç”¨ï¼‰
        self.reranker = SentenceTransformerRerank(
            model="BAAI/bge-reranker-base",
            top_n=rerank_top_k
        )
        
        # åˆå§‹åŒ–LLMï¼ˆç”¨äºHyDEï¼‰
        if use_hyde:
            if Settings.llm is None:
                Settings.llm = Ollama(
                    model="qwen2",
                    base_url="http://localhost:11434",
                    request_timeout=600.0
                )
    
    def _rewrite_query_hyde(self, query: str) -> str:
        """
        HyDEæŸ¥è¯¢é‡å†™ï¼šå°†ç”¨æˆ·æŸ¥è¯¢è½¬æ¢ä¸ºå‡è®¾æ€§æ–‡æ¡£
        """
        if not self.use_hyde:
            return query
        
        try:
            prompt = f"""åŸºäºä»¥ä¸‹ç”¨æˆ·æŸ¥è¯¢ï¼Œç”Ÿæˆä¸€æ®µå‡è®¾æ€§çš„ç”µè§†å‰§æè¿°æ–‡æ¡£ï¼Œè¿™æ®µæ–‡æ¡£åº”è¯¥ï¼š
1. åŒ…å«ç”¨æˆ·æŸ¥è¯¢ä¸­çš„å…³é”®å…ƒç´ 
2. æ‰©å±•ç›¸å…³çš„å‰§æƒ…ã€äººç‰©ã€é£æ ¼ç­‰ç»†èŠ‚
3. ç”¨è‡ªç„¶çš„ä¸­æ–‡æè¿°

ç”¨æˆ·æŸ¥è¯¢ï¼š{query}

å‡è®¾æ€§æ–‡æ¡£ï¼š"""
            
            response = Settings.llm.complete(prompt)
            rewritten_query = str(response).strip()
            logger.info(f"HyDEæŸ¥è¯¢é‡å†™: {query} -> {rewritten_query[:100]}...")
            return rewritten_query
        except Exception as e:
            logger.warning(f"HyDEæŸ¥è¯¢é‡å†™å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹æŸ¥è¯¢")
            return query
    
    def _retrieve_from_index(
        self,
        index: VectorStoreIndex,
        query_bundle: QueryBundle,
        filters: Optional[MetadataFilters] = None
    ) -> List[NodeWithScore]:
        """ä»å•ä¸ªç´¢å¼•æ£€ç´¢"""
        retriever = VectorIndexRetriever(
            index=index,
            similarity_top_k=self.similarity_top_k,
            filters=filters
        )
        return retriever.retrieve(query_bundle)
    
    def _apply_rerank(
        self,
        nodes: List[NodeWithScore],
        query_bundle: QueryBundle
    ) -> List[NodeWithScore]:
        """åº”ç”¨é‡æ’åº"""
        if not nodes:
            return nodes
        
        try:
            # Rerankeréœ€è¦Nodeå¯¹è±¡åˆ—è¡¨
            node_list = [node.node for node in nodes]
            reranked_nodes = self.reranker.postprocess_nodes(
                node_list,
                query_bundle=query_bundle
            )
            
            # è½¬æ¢å›NodeWithScoreæ ¼å¼ï¼Œä¿æŒæ–°çš„æ’åº
            reranked_with_scores = []
            node_id_to_original = {n.node.node_id: n for n in nodes}
            
            for node in reranked_nodes:
                original_node = node_id_to_original.get(node.node_id)
                if original_node:
                    # åˆ›å»ºæ–°çš„NodeWithScoreï¼Œä½¿ç”¨rerankåçš„é¡ºåº
                    from llama_index.core.schema import NodeWithScore
                    new_node = NodeWithScore(
                        node=node,
                        score=original_node.score if hasattr(original_node, 'score') and original_node.score else 0.5
                    )
                    reranked_with_scores.append(new_node)
            
            # å¦‚æœrerankæˆåŠŸï¼Œè¿”å›rerankç»“æœï¼›å¦åˆ™è¿”å›åŸå§‹ç»“æœ
            if reranked_with_scores:
                return reranked_with_scores[:self.rerank_top_k]
            else:
                # å¦‚æœrerankå¤±è´¥ï¼Œè¿”å›åŸå§‹ç»“æœçš„å‰top_k
                return nodes[:self.rerank_top_k]
        except Exception as e:
            logger.warning(f"é‡æ’åºå¤±è´¥: {e}ï¼Œè¿”å›åŸå§‹ç»“æœ")
            return nodes[:self.rerank_top_k]
    
    def _filter_by_similarity(
        self,
        nodes: List[NodeWithScore]
    ) -> List[NodeWithScore]:
        """æŒ‰ç›¸ä¼¼åº¦é˜ˆå€¼è¿‡æ»¤"""
        filtered = []
        for node in nodes:
            score = node.score if hasattr(node, 'score') and node.score else 0
            if score >= self.similarity_cutoff:
                filtered.append(node)
        return filtered
    
    def _merge_and_deduplicate(
        self,
        rich_nodes: List[NodeWithScore],
        basic_nodes: List[NodeWithScore]
    ) -> List[NodeWithScore]:
        """åˆå¹¶å¹¶å»é‡"""
        seen_ids = set()
        merged = []
        
        # å¯Œæ–‡æœ¬ä¼˜å…ˆ
        for node in rich_nodes:
            node_id = node.node.node_id
            if node_id not in seen_ids:
                # æå‡å¯Œæ–‡æœ¬ä¼˜å…ˆçº§
                if hasattr(node, 'score') and node.score:
                    node.score = node.score * 1.1
                merged.append(node)
                seen_ids.add(node_id)
        
        # æ·»åŠ åŸºç¡€ç´¢å¼•ç»“æœ
        for node in basic_nodes:
            node_id = node.node.node_id
            if node_id not in seen_ids:
                merged.append(node)
                seen_ids.add(node_id)
        
        # æŒ‰åˆ†æ•°æ’åº
        merged.sort(key=lambda x: x.score if hasattr(x, 'score') and x.score else 0, reverse=True)
        return merged
    
    def _add_episode_context(self, nodes: List[NodeWithScore]) -> List[NodeWithScore]:
        """ä¸ºepisodeèŠ‚ç‚¹æ·»åŠ å‰§é›†ä¸Šä¸‹æ–‡"""
        for node in nodes:
            if node.node.metadata.get('type') == 'episode':
                parent_title = node.node.metadata.get('parent_title', 'æœªçŸ¥å‰§é›†')
                ep_number = node.node.metadata.get('ep_number', '')
                ep_title = node.node.metadata.get('episode_title', '')
                original_text = node.node.text
                node.node.text = (
                    f"ã€æ¥è‡ªå‰§é›†ï¼š{parent_title}ï¼Œç¬¬{ep_number}é›†"
                    + (f"ã€Š{ep_title}ã€‹" if ep_title else "")
                    + "ã€‘\n" + original_text
                )
        return nodes
    
    def retrieve_lightning(
        self,
        query: str,
        scope: Literal["rich", "basic", "both"] = "both"
    ) -> List[NodeWithScore]:
        """
        âš¡ æé€Ÿæ¨¡å¼ï¼šçº¯å‘é‡æ£€ç´¢
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            scope: æ£€ç´¢èŒƒå›´ ("rich", "basic", "both")
        
        Returns:
            æ£€ç´¢åˆ°çš„èŠ‚ç‚¹åˆ—è¡¨ï¼ˆå·²æŒ‰ç›¸ä¼¼åº¦æ’åºï¼‰
        """
        query_bundle = QueryBundle(query)
        all_nodes = []
        
        # ä»å¯Œæ–‡æœ¬ç´¢å¼•æ£€ç´¢
        if scope in ["rich", "both"]:
            rich_nodes = self._retrieve_from_index(self.rich_text_index, query_bundle)
            all_nodes.extend(rich_nodes)
        
        # ä»åŸºç¡€ç´¢å¼•æ£€ç´¢
        if scope in ["basic", "both"] and self.basic_index:
            basic_nodes = self._retrieve_from_index(self.basic_index, query_bundle)
            all_nodes.extend(basic_nodes)
        
        # åˆå¹¶å»é‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if scope == "both" and self.basic_index and len(all_nodes) > 0:
            # åˆ†ç¦»richå’ŒbasicèŠ‚ç‚¹
            rich_list = []
            basic_list = []
            for n in all_nodes:
                if n.node.metadata.get('index_type') == 'rich_text':
                    rich_list.append(n)
                else:
                    basic_list.append(n)
            if rich_list and basic_list:
                all_nodes = self._merge_and_deduplicate(rich_list, basic_list)
            elif rich_list:
                all_nodes = rich_list
            elif basic_list:
                all_nodes = basic_list
        
        # ç›¸ä¼¼åº¦è¿‡æ»¤ï¼ˆåªè¿‡æ»¤ç‰¹åˆ«ä½çš„ï¼‰
        all_nodes = self._filter_by_similarity(all_nodes)
        
        # æ·»åŠ episodeä¸Šä¸‹æ–‡
        all_nodes = self._add_episode_context(all_nodes)
        
        # è¿”å›top 20ï¼ˆæé€Ÿæ¨¡å¼ä¸éœ€è¦rerankï¼‰
        return all_nodes[:20]
    
    def retrieve_deep(
        self,
        query: str,
        scope: Literal["rich", "basic", "both"] = "both"
    ) -> List[NodeWithScore]:
        """
        ğŸ§  æ·±åº¦æ¨¡å¼ï¼šHyDEæŸ¥è¯¢é‡å†™ + åŒè½¨æ£€ç´¢ + Rerank
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            scope: æ£€ç´¢èŒƒå›´
        
        Returns:
            é‡æ’åºåçš„èŠ‚ç‚¹åˆ—è¡¨
        """
        # 1. HyDEæŸ¥è¯¢é‡å†™ï¼ˆå¯é€‰ï¼‰
        rewritten_query = self._rewrite_query_hyde(query)
        query_bundle = QueryBundle(rewritten_query)
        
        # 2. ä»ä¸¤ä¸ªç´¢å¼•æ£€ç´¢
        rich_nodes = []
        basic_nodes = []
        
        if scope in ["rich", "both"]:
            rich_nodes = self._retrieve_from_index(self.rich_text_index, query_bundle)
        
        if scope in ["basic", "both"] and self.basic_index:
            basic_nodes = self._retrieve_from_index(self.basic_index, query_bundle)
        
        # 3. åˆå¹¶å»é‡
        if scope == "both" and self.basic_index:
            all_nodes = self._merge_and_deduplicate(rich_nodes, basic_nodes)
        else:
            all_nodes = rich_nodes if scope == "rich" else basic_nodes
        
        # 4. ç›¸ä¼¼åº¦è¿‡æ»¤ï¼ˆå…ˆä¸è¿‡æ»¤ï¼Œè®©rerankå¤„ç†ï¼‰
        # all_nodes = self._filter_by_similarity(all_nodes)
        
        # 5. Reranké‡æ’åºï¼ˆä½¿ç”¨åŸå§‹æŸ¥è¯¢ï¼‰
        if all_nodes:
            original_query_bundle = QueryBundle(query)
            all_nodes = self._apply_rerank(all_nodes, original_query_bundle)
        else:
            logger.warning("æ£€ç´¢ç»“æœä¸ºç©º")
        
        # 6. ç›¸ä¼¼åº¦è¿‡æ»¤ï¼ˆrerankåï¼‰
        all_nodes = self._filter_by_similarity(all_nodes)
        
        # 7. æ·»åŠ episodeä¸Šä¸‹æ–‡
        all_nodes = self._add_episode_context(all_nodes)
        
        return all_nodes
    
    def retrieve_filter(
        self,
        query: str,
        filters: Optional[Dict] = None,
        scope: Literal["rich", "basic", "both"] = "both"
    ) -> List[NodeWithScore]:
        """
        ğŸ¯ ç­›é€‰æ¨¡å¼ï¼šMetadataè¿‡æ»¤ + å‘é‡æ’åº
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            filters: ç­›é€‰æ¡ä»¶ï¼Œä¾‹å¦‚ {"year": "2022", "genre": "æ‚¬ç–‘"}
            scope: æ£€ç´¢èŒƒå›´
        
        Returns:
            ç­›é€‰åçš„èŠ‚ç‚¹åˆ—è¡¨
        """
        query_bundle = QueryBundle(query)
        
        # æ„å»ºMetadataè¿‡æ»¤å™¨
        metadata_filters = None
        if filters:
            filter_list = []
            for key, value in filters.items():
                filter_list.append({
                    "key": key,
                    "value": value,
                    "operator": "=="
                })
            if filter_list:
                metadata_filters = MetadataFilters(
                    filters=filter_list,
                    condition=FilterCondition.AND
                )
        
        # æ£€ç´¢
        all_nodes = []
        
        if scope in ["rich", "both"]:
            rich_nodes = self._retrieve_from_index(
                self.rich_text_index,
                query_bundle,
                filters=metadata_filters
            )
            all_nodes.extend(rich_nodes)
        
        if scope in ["basic", "both"] and self.basic_index:
            basic_nodes = self._retrieve_from_index(
                self.basic_index,
                query_bundle,
                filters=metadata_filters
            )
            all_nodes.extend(basic_nodes)
        
        # åˆå¹¶å»é‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if scope == "both" and self.basic_index and len(all_nodes) > 0:
            # åˆ†ç¦»richå’ŒbasicèŠ‚ç‚¹
            rich_list = []
            basic_list = []
            for n in all_nodes:
                if n.node.metadata.get('index_type') == 'rich_text':
                    rich_list.append(n)
                else:
                    basic_list.append(n)
            if rich_list and basic_list:
                all_nodes = self._merge_and_deduplicate(rich_list, basic_list)
            elif rich_list:
                all_nodes = rich_list
            elif basic_list:
                all_nodes = basic_list
        
        # ç›¸ä¼¼åº¦è¿‡æ»¤ï¼ˆåªè¿‡æ»¤ç‰¹åˆ«ä½çš„ï¼‰
        all_nodes = self._filter_by_similarity(all_nodes)
        
        # æ·»åŠ episodeä¸Šä¸‹æ–‡
        all_nodes = self._add_episode_context(all_nodes)
        
        # è¿”å›top 20ï¼ˆç­›é€‰æ¨¡å¼ä¸éœ€è¦rerankï¼‰
        return all_nodes[:20]
    
    def retrieve(
        self,
        query: str,
        mode: Literal["lightning", "deep", "filter"] = "deep",
        scope: Literal["rich", "basic", "both"] = "both",
        filters: Optional[Dict] = None
    ) -> List[NodeWithScore]:
        """
        ç»Ÿä¸€æ£€ç´¢æ¥å£
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            mode: æ£€ç´¢æ¨¡å¼ ("lightning", "deep", "filter")
            scope: æ£€ç´¢èŒƒå›´
            filters: ç­›é€‰æ¡ä»¶ï¼ˆä»…filteræ¨¡å¼ä½¿ç”¨ï¼‰
        
        Returns:
            æ£€ç´¢ç»“æœ
        """
        if mode == "lightning":
            return self.retrieve_lightning(query, scope=scope)
        elif mode == "deep":
            return self.retrieve_deep(query, scope=scope)
        elif mode == "filter":
            return self.retrieve_filter(query, filters=filters, scope=scope)
        else:
            raise ValueError(f"æœªçŸ¥çš„æ£€ç´¢æ¨¡å¼: {mode}")

